# -*- coding: utf-8 -*-
"""Telco_Churn_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1q-KjjEQeYvzXBmsVc5MaFeqob4Du65GD

# Görev 1 : Keşifçi Veri Analizi
# Adım 1: Numerik ve kategorik değişkenleri yakalayınız.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import GridSearchCV, cross_validate
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
!pip install catboost
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,roc_auc_score
from catboost import CatBoostClassifier
from lightgbm import LGBMClassifier
from xgboost import XGBClassifier
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, RobustScaler
from sklearn.linear_model import LinearRegression, Ridge, Lasso, LassoCV
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
from catboost import CatBoostRegressor

from sklearn.neighbors import KNeighborsRegressor
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor


pd.set_option('display.max_columns', None)
pd.set_option('display.width', 170)
pd.set_option('display.max_rows', None)
pd.set_option('display.float_format', lambda x: '%.3f' % x)
import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)
warnings.filterwarnings("ignore", category=FutureWarning)
from google.colab import drive
#drive.mount('/content/drive')
path = '/content/Telco-Customer-Churn.csv'
df = pd.read_csv(path)

df.head()

df.shape

def check_df(dataframe, head=5):
    print("##################### Shape #####################")
    print(dataframe.shape)
    print("##################### Types #####################")
    print(dataframe.dtypes)
    print("##################### Head #####################")
    print(dataframe.head(head))
    print("##################### Tail #####################")
    print(dataframe.tail(head))
    print("##################### NA #####################")
    print(dataframe.isnull().sum())
    print("##################### Quantiles #####################")
    print(dataframe.quantile([0, 0.05, 0.50, 0.95, 0.99, 1]).T)

check_df(df)

"""### Adım 2: Gerekli düzenlemeleri yapınız. (Tip hatası olan değişkenler gibi)kalın metin"""

# TotalCharges sayısal bir değişken olmalı
df["TotalCharges"] = pd.to_numeric(df["TotalCharges"], errors='coerce')

# Bağımlı değişkenimizi binary değişkene çevirelim. (Encode da edilebilir.)
df["Churn"] = df["Churn"].apply(lambda x: 1 if x == "Yes" else 0)

# Adım 3: Numerik ve kategorik değişkenlerin veri içindeki dağılımını gözlemleyiniz.
def grab_col_names(dataframe, cat_th=10, car_th=20):
    """

    Veri setindeki kategorik, numerik ve kategorik fakat kardinal değişkenlerin isimlerini verir.
    Not: Kategorik değişkenlerin içerisine numerik görünümlü kategorik değişkenler de dahildir.

    Parameters
    ------
        dataframe: dataframe
                Değişken isimleri alınmak istenilen dataframe
        cat_th: int, optional
                numerik fakat kategorik olan değişkenler için sınıf eşik değeri
        car_th: int, optional
                kategorik fakat kardinal değişkenler için sınıf eşik değeri

    Returns
    ------
        cat_cols: list
                Kategorik değişken listesi
        num_cols: list
                Numerik değişken listesi
        cat_but_car: list
                Kategorik görünümlü kardinal değişken listesi

    Examples
    ------
        import seaborn as sns
        df = sns.load_dataset("iris")
        print(grab_col_names(df))


    Notes
    ------
        cat_cols + num_cols + cat_but_car = toplam değişken sayısı
        num_but_cat cat_cols'un içerisinde.

    """
    # cat_cols, cat_but_car
    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == "O"]
    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and dataframe[col].dtypes != "O"]
    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and dataframe[col].dtypes == "O"]
    cat_cols = cat_cols + num_but_cat
    cat_cols = [col for col in cat_cols if col not in cat_but_car]

    # num_cols
    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != "O"]
    num_cols = [col for col in num_cols if col not in num_but_cat]

    print(f"Observations: {dataframe.shape[0]}")
    print(f"Variables: {dataframe.shape[1]}")
    print(f'cat_cols: {len(cat_cols)}')
    print(f'num_cols: {len(num_cols)}')
    print(f'cat_but_car: {len(cat_but_car)}')
    print(f'num_but_cat: {len(num_but_cat)}')

    return cat_cols, num_cols, cat_but_car

cat_cols, num_cols, cat_but_car = grab_col_names(df)

cat_cols
df[cat_cols].head()

num_cols

# KATEGORİK DEĞİŞKENLERİN ANALİZİ
def cat_summary(dataframe, col_name, plot=False):
    print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),
                        "Ratio": 100 * dataframe[col_name].value_counts() / len(dataframe)}))
    print("##########################################")
    if plot:
        sns.countplot(x=dataframe[col_name], data=dataframe)
        plt.show()

for col in cat_cols:
    cat_summary(df, col, plot=True)

# NUMERİK DEĞİŞKENLERİN ANALİZİ
def num_summary(dataframe, numerical_col, plot=False):
    quantiles = [0.05, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 0.99]
    print(dataframe[numerical_col].describe(quantiles).T)

    if plot:
        dataframe[numerical_col].hist(bins=20)
        plt.xlabel(numerical_col)
        plt.title(numerical_col)
        plt.show()

for col in num_cols:
    num_summary(df, col, plot=True)

# Adım 4: Kategorik değişkenler ile hedef değişken incelemesini yapınız.

def target_summary_with_num(dataframe, target, numerical_col):
    print(dataframe.groupby(target).agg({numerical_col: "mean"}), end="\n\n\n")

for col in num_cols:
    target_summary_with_num(df, "Churn", col)

# KATEGORİK DEĞİŞKENLERİN TARGET GÖRE ANALİZİ
##################################

def target_summary_with_cat(dataframe, target, categorical_col):
    print(categorical_col)
    print(pd.DataFrame({"TARGET_MEAN": dataframe.groupby(categorical_col)[target].mean(),
                        "Count": dataframe[categorical_col].value_counts(),
                        "Ratio": 100 * dataframe[categorical_col].value_counts() / len(dataframe)}), end="\n\n\n")

for col in cat_cols:
    target_summary_with_cat(df, "Churn", col)

# Kategorik değişkenleri "Churn" özelinde görselleştirip inceleyelim
for col in cat_cols:
    graph = pd.crosstab(index=df['Churn'], columns=df[col]).plot.bar(figsize=(7, 4), rot=0)
    plt.show()

# Adım 5: Aykırı gözlem var mı inceleyiniz.
##################################

def outlier_thresholds(dataframe, col_name, q1=0.10, q3=0.90):
    quartile1 = dataframe[col_name].quantile(q1)
    quartile3 = dataframe[col_name].quantile(q3)
    interquantile_range = quartile3 - quartile1
    up_limit = quartile3 + 1.5 * interquantile_range
    low_limit = quartile1 - 1.5 * interquantile_range
    return low_limit, up_limit


def check_outlier(dataframe, col_name):
    low_limit, up_limit = outlier_thresholds(dataframe, col_name)
    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):
        return True
    else:
        return False

for col in num_cols:
    print(col, ": ", check_outlier(df, col))

# Sayısal değişkenlerde aykırı değerin olmadığını gözlemliyoruz.

# Adım 6: Eksik gözlem var mı inceleyiniz.
##################################

def missing_values_table(dataframe, na_name=False):
    na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]

    n_miss = dataframe[na_columns].isnull().sum().sort_values(ascending=False)
    ratio = (dataframe[na_columns].isnull().sum() / dataframe.shape[0] * 100).sort_values(ascending=False)
    missing_df = pd.concat([n_miss, np.round(ratio, 2)], axis=1, keys=['n_miss', 'ratio'])
    print(missing_df, end="\n")

    if na_name:
        return na_columns

missing_values_table(df)

# Görev 2 : Feature Engineering
##################################
# Adım 1: Eksik ve aykırı gözlemler için gerekli işlemleri yapınız.
##################################

for col in num_cols:
    print(col, ": ", check_outlier(df, col))
# Aykırı gözlem yok.

index_nan = df[df.isnull().any(axis=1)].index
df2 = pd.read_csv("/content/Telco-Customer-Churn.csv")
df2.iloc[index_nan]

df["TotalCharges"].fillna(df.iloc[index_nan]["MonthlyCharges"], inplace=True)

# Correlation
df[num_cols].corr()

# Korelasyon Matrisi
f, ax = plt.subplots(figsize=[8, 8])
sns.heatmap(df.corr(), annot=True, fmt=".2f", ax=ax, cmap="RdPu")
ax.set_title("Correlation Matrix", fontsize=20)
plt.show()

# Tenure ve Monthly Charges arasındaki korelasyon düşük çıkarken Total Charges arasındaki ilişki çok yüksek çıktı.
# Ayrıca Monthly Charges ile Total Charges arasında beklenen bir korelasyon var.

df.corrwith(df["Churn"]).sort_values(ascending=False)

# Adım 2: Yeni değişkenler oluşturunuz.
##################################
df.columns = [col.upper() for col in df.columns]

df.loc[(df["TENURE"] >= 0) & (df["TENURE"] <= 12), "NEW_TENURE_YEAR"] = "1 Year"
df.loc[(df["TENURE"] > 12) & (df["TENURE"] <= 24), "NEW_TENURE_YEAR"] = "2 Year"
df.loc[(df["TENURE"] > 24) & (df["TENURE"] <= 36), "NEW_TENURE_YEAR"] = "3 Year"
df.loc[(df["TENURE"] > 36) & (df["TENURE"] <= 48), "NEW_TENURE_YEAR"] = "4 Year"
df.loc[(df["TENURE"] > 48) & (df["TENURE"] <= 60), "NEW_TENURE_YEAR"] = "5 Year"
df.loc[(df["TENURE"] > 60) & (df["TENURE"] <= 72), "NEW_TENURE_YEAR"] = "6 Year"

df.TENURE.max() #72

# Kontratı 1 veya 2 yıllık müşterileri Engaged olarak belirtme
df["NEW_ENGAGED"] = df["CONTRACT"].apply(lambda x: 1 if x in ["One year", "Two year"] else 0)

# Herhangi bir destek, yedek veya koruma almayan kişiler
df["NEW_NOPROT"] = df.apply(lambda x: 1 if (x["ONLINEBACKUP"] != "Yes") or (x["DEVICEPROTECTION"] != "Yes") or (x["TECHSUPPORT"] != "Yes") else 0, axis=1)

# Aylık sözleşmesi bulunan ve genç olan müşteriler
df["NEW_YOUNG_NOT_ENGAGED"] = df.apply(lambda x: 1 if (x["NEW_ENGAGED"] == 0) and (x["SENIORCITIZEN"] == 0) else 0, axis=1)

# Kişinin toplam aldığı servis sayısı
df['NEW_TOTALSERVICES'] = (df[['PHONESERVICE', 'INTERNETSERVICE', 'ONLINESECURITY',
                                       'ONLINEBACKUP', 'DEVICEPROTECTION', 'TECHSUPPORT',
                                       'STREAMINGTV', 'STREAMINGMOVIES']] == 'Yes').sum(axis=1)


# Herhangi bir streaming hizmeti alan kişiler
df["NEW_FLAG_ANY_STREAMING"] = df.apply(lambda x: 1 if (x["STREAMINGTV"] == "Yes") or (x["STREAMINGMOVIES"] == "Yes") else 0, axis=1)

# Kişi otomatik ödeme yapıyor mu?
df["NEW_FLAG_AUTOPAYMENT"] = df["PAYMENTMETHOD"].apply(lambda x: 1 if x in ["Bank transfer (automatic)", "Credit card (automatic)"] else 0)

# ortalama aylık ödeme
df["NEW_AVG_CHARGES"] = df["TOTALCHARGES"] / (df["TENURE"] + 1)

# Güncel Fiyatın ortalama fiyata göre artışı
df["NEW_INCREASE"] = df["NEW_AVG_CHARGES"] / df["MONTHLYCHARGES"]

# Servis başına ücret
df["NEW_AVG_SERVICE_FEE"] = df["MONTHLYCHARGES"] / (df['NEW_TOTALSERVICES'] + 1)


# Şirket hizmet sektöründe yer aldığı için verdiği hizmetin kalitesinden memnuniyet durumu önemli.
# Memnuniyet durumunu tahmin edebilecek değişkenler oluşturalım.
# Öncelikle contract değişkenini rahat kullanabilmek adına sayısal değişkene çevirelim.

df.loc[(df['CONTRACT'] == "Month-to-month"), "NEW_CONTRACT"] = 1
df.loc[(df['CONTRACT'] == "One year"), "NEW_CONTRACT"] = 12
df.loc[(df['CONTRACT'] == "Two year"), "NEW_CONTRACT"] = 24

# Contract süresi bitmeden churn olanları aldığı hizmetten memnun kalmamış sayabiliriz.

df.loc[(df["NEW_CONTRACT"] == 1) & (df["TENURE"] <= 2) & (df["CHURN"] == 1), "NEW_DISSATISFACTION1"] = 1
df.loc[(df["NEW_CONTRACT"] == 12) & (df["TENURE"] <= 12) & (df["CHURN"] == 1), "NEW_DISSATISFACTION1"] = 1
df.loc[(df["NEW_CONTRACT"] == 24) & (df["TENURE"] <= 24) & (df["CHURN"] == 1), "NEW_DISSATISFACTION1"] = 1
df["NEW_DISSATISFACTION1"] = df["NEW_DISSATISFACTION1"].fillna(0)
df["NEW_DISSATISFACTION1"].value_counts()

df.head()

# Adım 3: Encoding işlemlerini gerçekleştiriniz.
##################################

# Yeniden değişkenlerimizi türlerine göre ayıralım.

cat_cols, num_cols, cat_but_car = grab_col_names(df)

# NEW_TotalServices değişkeni cat_cols arasında yer almış fakat numeric bir değişken onun yerini değiştirelim.
cat_cols.remove("NEW_TOTALSERVICES")
num_cols.append("NEW_TOTALSERVICES")

# Churn bağımlı değişkenimiz olduğu için onu encode etmemize şu an için gerek yok.
cat_cols.remove("CHURN")

def one_hot_encoder(dataframe, categorical_cols, drop_first=False):
    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)
    return dataframe

df = one_hot_encoder(df, cat_cols, drop_first=True)

df.head()

df.shape

def missing_values_df(dataframe, na_name=False):
    na_column = [col for col in dataframe.columns if
                 dataframe[col].isnull().sum() > 0]  # missing değer iceren kolon adı
    n_miss = dataframe[na_column].isnull().sum().sort_values(ascending=False)  # boş gözlem sayısı
    ratio = (dataframe[na_column].isnull().sum() * 100 / dataframe.shape[0]).sort_values(ascending=False)
    missing_df = pd.DataFrame({"n_miss": n_miss, "n_miss_ratio": ratio})
    # missing_df = pd.concat([n_miss, np.round(ratio, 2)], axis=1, keys=['n_miss', 'ratio'])
    print(missing_df, end="\n")
    if na_name:
        return na_column

missing_values_df(df)

# Rare Encoding
##############################################################

cat_cols = grab_col_names(df)[0]

 # Her bir kategorik değişkenin sınıf frekanslarına ve target değişken ortalamasına bakalım:
def rare_analyser(dataframe, target, cat_cols):
    for col in cat_cols:
        print(col, ":", len(dataframe[col].value_counts()))
        print(pd.DataFrame({"COUNT": dataframe[col].value_counts(),
                            "RATIO": dataframe[col].value_counts() / len(dataframe),
                            "TARGET_MEAN": dataframe.groupby(col)[target].mean()}), end="\n\n\n")

rare_analyser(df, "CHURN", cat_cols)


# Sınıf sayısının tek olması ya da 2 sınıflı değişkenden sınıflardan birinin frekanslarının %1 in altında olması
# bu değişkenin açıklayıcılığının olmadığını gösterir, bu değişkenleri silebiliriz:

useless_cols = [col for col in df.columns if ((df[col].nunique() == 2
                                            and (df[col].value_counts() / len(df) < 0.01).any(axis=None))
                                            | df[col].nunique() == 1)]
print(useless_cols)
df.drop(useless_cols, axis=1, inplace=True)

# useless_cols bos geldi

# Adım 4: Numerik değişkenler için standartlaştırma yapınız.
##################################

scaler = RobustScaler()# Medyanı çıkar iqr'a böl.
df[num_cols] = scaler.fit_transform(df[num_cols])
df.head()

# Görev 3 : Modelleme
##################################
# Adım 1: Sınıflandırma algoritmaları ile modeller kurup, accuracy skorlarını inceleyip. En iyi 4 modeli seçiniz.
##################################

y = df["CHURN"]
X = df.drop(["CHURN", "CUSTOMERID"], axis=1)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=17)

catboost_model = CatBoostClassifier(verbose=False, random_state=12345).fit(X_train, y_train)
y_pred = catboost_model.predict(X_test)

print(f"Accuracy: {round(accuracy_score(y_pred, y_test), 4)}")
print(f"Recall: {round(recall_score(y_pred,y_test),4)}")
print(f"Precision: {round(precision_score(y_pred,y_test), 4)}")
print(f"F1: {round(f1_score(y_pred,y_test), 4)}")
print(f"Auc: {round(roc_auc_score(y_pred,y_test), 4)}")

lgb_model = LGBMRegressor().fit(X, y)
y_pred = lgb_model.predict(X)

def plot_importance(model, features, num=len(X), save=False):
    feature_imp = pd.DataFrame({'Value': model.feature_importances_, 'Feature': features.columns})
    plt.figure(figsize=(6, 6))
    sns.set(font_scale=1)
    sns.barplot(x="Value", y="Feature", data=feature_imp.sort_values(by="Value",
                                                                     ascending=False)[0:num]) # num argümanı ile barplot üzerinde kaç değişkeni göstereceğimizi seçebiliriz.
    plt.title("Features")
    plt.title(f"Features for {type(model).__name__}") # modelin __name__ metodu ile adını döndürür
    plt.tight_layout()
    plt.show()
    if save:
        plt.savefig('importances.png')

plot_importance(lgb_model, X, 5)

# Models

models = [('LR', LogisticRegression(random_state=46)),
          ('KNN', KNeighborsClassifier()),
          ('CART', DecisionTreeClassifier(random_state=46)),
          ('RF', RandomForestClassifier(random_state=46)),
          ('SVM', SVC(gamma='auto', random_state=46)),
          ('XGB', XGBClassifier(random_state=46)),
          ("LightGBM", LGBMClassifier(random_state=46)),
          ("CatBoost", CatBoostClassifier(verbose=False, random_state=46))]

# Adım 1: Sınıflandırma algoritmaları ile modeller kurup, accuracy skorlarını inceleyip. En iyi 4 modeli seçiniz.

for name, model in models:
    cv_results = cross_validate(model, X, y, cv=10, scoring=["accuracy", "f1", "roc_auc", "precision", "recall"])
    print(f"########## {name} ##########")
    print(f"Accuracy: {round(cv_results['test_accuracy'].mean(), 4)}")
    print(f"Auc: {round(cv_results['test_roc_auc'].mean(), 4)}")
    print(f"Recall: {round(cv_results['test_recall'].mean(), 4)}")
    print(f"Precision: {round(cv_results['test_precision'].mean(), 4)}")
    print(f"F1: {round(cv_results['test_f1'].mean(), 4)}")

# LR, RF, XGB, LightGBM, CatBoost

# Adım 2: Seçtiğiniz modeller ile hiperparametre optimizasyonu gerçekleştirin ve bulduğunuz hiparparametreler ile modeli tekrar kurunuz.
# Random Forests
rf_model = RandomForestClassifier(random_state=17)

rf_params = {"max_depth": [5, 8],
             "max_features": [3, 7, "auto"],
             "min_samples_split": [8, 15, 20],
             "n_estimators": [100, 500]}

rf_best_grid = GridSearchCV(rf_model, rf_params, cv=5, n_jobs=-1, verbose=True).fit(X, y)

rf_best_grid.best_params_

rf_best_grid.best_score_

rf_final = rf_model.set_params(**rf_best_grid.best_params_, random_state=17).fit(X, y)


cv_results = cross_validate(rf_final, X, y, cv=10, scoring=["accuracy", "f1", "roc_auc"])
cv_results['test_accuracy'].mean()

cv_results['test_f1'].mean()

cv_results['test_roc_auc'].mean()

# XGBoost

xgboost_model = XGBClassifier(random_state=17, use_label_encoder=False)
xgboost_model.get_params()

cv_results = cross_validate(xgboost_model, X, y, cv=5, scoring=["accuracy", "f1", "roc_auc"])
cv_results['test_accuracy'].mean()

cv_results['test_f1'].mean()

cv_results['test_roc_auc'].mean()

xgboost_params = {"learning_rate": [0.1, 0.01],
                  "max_depth": [5, 8],
                  "n_estimators": [100, 500, 1000],
                  "colsample_bytree": [0.7, 1]}

xgboost_best_grid = GridSearchCV(xgboost_model, xgboost_params, cv=5, n_jobs=-1, verbose=True).fit(X, y)

xgboost_final = xgboost_model.set_params(**xgboost_best_grid.best_params_, random_state=17).fit(X, y)

cv_results = cross_validate(xgboost_final, X, y, cv=5, scoring=["accuracy", "f1", "roc_auc"])
cv_results['test_accuracy'].mean()

cv_results['test_f1'].mean()

cv_results['test_roc_auc'].mean()

# LightGBM

lgbm_model = LGBMClassifier(random_state=17)
lgbm_model.get_params()

cv_results = cross_validate(lgbm_model, X, y, cv=5, scoring=["accuracy", "f1", "roc_auc"])

cv_results['test_accuracy'].mean()

cv_results['test_f1'].mean()

cv_results['test_roc_auc'].mean()

lgbm_params = {"learning_rate": [0.01, 0.1],
               "n_estimators": [100, 300, 500, 1000],# 10000lere kadar dene
               "colsample_bytree": [0.5, 0.7, 1]}

lgbm_best_grid = GridSearchCV(lgbm_model, lgbm_params, cv=5, n_jobs=-1, verbose=True).fit(X, y)

lgbm_final = lgbm_model.set_params(**lgbm_best_grid.best_params_, random_state=17).fit(X, y)

cv_results = cross_validate(lgbm_final, X, y, cv=5, scoring=["accuracy", "f1", "roc_auc"])

cv_results['test_accuracy'].mean()

lgbm_params

cv_results['test_f1'].mean()

cv_results['test_roc_auc'].mean()

# Hiperparametre yeni değerlerle
lgbm_params = {"learning_rate": [0.01, 0.1],
               "n_estimators": [200, 300, 350, 400],
               "colsample_bytree": [0.5, 0.7, 1]}

lgbm_best_grid = GridSearchCV(lgbm_model, lgbm_params, cv=5, n_jobs=-1, verbose=True).fit(X, y)

lgbm_final = lgbm_model.set_params(**lgbm_best_grid.best_params_, random_state=17).fit(X, y)

cv_results = cross_validate(lgbm_final, X, y, cv=5, scoring=["accuracy", "f1", "roc_auc"])

cv_results['test_accuracy'].mean()

cv_results['test_f1'].mean()

cv_results['test_roc_auc'].mean()

# CatBoost

catboost_model = CatBoostClassifier(random_state=17, verbose=False)

cv_results = cross_validate(catboost_model, X, y, cv=5, scoring=["accuracy", "f1", "roc_auc"])

cv_results['test_accuracy'].mean()

cv_results['test_f1'].mean()

cv_results['test_roc_auc'].mean()

catboost_params = {"iterations": [200, 500],
                   "learning_rate": [0.01, 0.1],
                   "depth": [3, 6]}


catboost_best_grid = GridSearchCV(catboost_model, catboost_params, cv=5, n_jobs=-1, verbose=True).fit(X, y)

catboost_final = catboost_model.set_params(**catboost_best_grid.best_params_, random_state=17).fit(X, y)

cv_results = cross_validate(catboost_final, X, y, cv=5, scoring=["accuracy", "f1", "roc_auc"])

cv_results['test_accuracy'].mean()

cv_results['test_f1'].mean()

cv_results['test_roc_auc'].mean()

# Feature Importance
################################################

def plot_importance(model, features, num=len(X), save=False):
    feature_imp = pd.DataFrame({'Value': model.feature_importances_, 'Feature': features.columns})
    plt.figure(figsize=(10, 10))
    sns.set(font_scale=1)
    sns.barplot(x="Value", y="Feature", data=feature_imp.sort_values(by="Value",
                                                                     ascending=False)[0:num])
    plt.title('Features')
    plt.tight_layout()
    plt.show()
    if save:
        plt.savefig('importances.png')

plot_importance(rf_final, X)
# plot_importance(gbm_final, X)
plot_importance(xgboost_final, X)
plot_importance(lgbm_final, X)
plot_importance(catboost_final, X)